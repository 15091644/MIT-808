{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25ed7185",
   "metadata": {},
   "source": [
    "### Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fd34ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04770a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment if not installed\n",
    "\n",
    "# !pip install wordcloud\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3aa260",
   "metadata": {},
   "source": [
    "### Import Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ca7b117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b05a30",
   "metadata": {},
   "source": [
    "### Read Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ce5769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_name = \"1.0-jp-initial-data-exploration\"\n",
    "\n",
    "dataset_1 = 'preprocessed_data_query-sdg-full-regexp_2022-03-15.csv' # _1, _2 etc.. as need to list more than one data set being read in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74cee14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jesse\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (10,11,26) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/processed/'+dataset_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d9ae4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autonomy and accountability in the regulation ...</td>\n",
       "      <td>This article examines the struggles of the Sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Intellectuals under fire</td>\n",
       "      <td>Looks at the status of intellectuals in South ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mode 2 knowledge and institutional life: takin...</td>\n",
       "      <td>This paper examines the response of a black un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Political symbolism as policy craft : explaini...</td>\n",
       "      <td>The policy literature in developing countries ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>School curriculum since apartheid : intersecti...</td>\n",
       "      <td>In the wake of South Africa's first non-racial...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Autonomy and accountability in the regulation ...   \n",
       "1                           Intellectuals under fire   \n",
       "2  Mode 2 knowledge and institutional life: takin...   \n",
       "3  Political symbolism as policy craft : explaini...   \n",
       "4  School curriculum since apartheid : intersecti...   \n",
       "\n",
       "                                             content  \n",
       "0  This article examines the struggles of the Sou...  \n",
       "1  Looks at the status of intellectuals in South ...  \n",
       "2  This paper examines the response of a black un...  \n",
       "3  The policy literature in developing countries ...  \n",
       "4  In the wake of South Africa's first non-racial...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['title','content']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd4d098",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1996c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to print \n",
    "\n",
    "#TODO: Change naming and comment on code\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        cloud_text = \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()\n",
    "    \n",
    "# Helper function to visualize the topics/themes\n",
    "def wordcloud_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        cloud_text = \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        # Create the wordcloud object\n",
    "        wordcloud = WordCloud(width=480, height=480, margin=0,background_color = 'white').generate(cloud_text)\n",
    "        fig1, ax1 = plt.subplots()\n",
    "        # Display the generated image:\n",
    "        ax1.imshow(wordcloud, interpolation='bilinear')\n",
    "        ax1.axis(\"off\") \n",
    "        plt.tight_layout(pad = 0) \n",
    "        plt.title(\"Topic %s\" % topic_idx,fontsize = 12)\n",
    "\n",
    "def fit_LDA(X, n_components):\n",
    "    lda_tfidf = LatentDirichletAllocation(n_components= n_components,    random_state=0).fit(X)\n",
    "\n",
    "    return lda_tfidf\n",
    "\n",
    "\n",
    "def tokenize(text): ## This just tokenizes the sentences to words and removes individual punctuations.\n",
    "    punctuations = list(string.punctuation)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [x for x in tokens if x not in punctuations]\n",
    "    stems = []\n",
    "    for item in tokens:\n",
    "        stems.append(WordNetLemmatizer().lemmatize(item, pos=\"v\")) # Change this stemmer/lemmatizer and see what happens\n",
    "    return stems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24f2fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jesse\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:489: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
      "C:\\Users\\jesse\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "# extract documents and drop nans if present to prevent an error\n",
    "documents = df.content.dropna()\n",
    "\n",
    "# set up vectorisor the abstracts. Here features are limited to 5000 and common words are removed\n",
    "vectorizer_tfidf_limit = TfidfVectorizer(max_features=5000,stop_words='english',tokenizer=tokenize)\n",
    "\n",
    "# vectorise \n",
    "vectorizer_tfidf_limit.fit(documents)\n",
    "\n",
    "X_dtm_tfidf_limit = vectorizer_tfidf_limit.transform(documents)\n",
    "\n",
    "tfidf_feature_names_limit = vectorizer_tfidf_limit.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef548d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of themes\n",
    "n_components = 17\n",
    "\n",
    "# number of top words considered\n",
    "num_top_words= 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b878b8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and transform LDA model\n",
    "lda_tfidf_limit = fit_LDA(X_dtm_tfidf_limit, n_components)\n",
    "X_lda_tfidf_limit_membership = lda_tfidf_limit.transform(X_dtm_tfidf_limit)\n",
    "\n",
    "# Print new topics\n",
    "print_top_words(lda_tfidf_limit, tfidf_feature_names_limit, num_top_words)\n",
    "wordcloud_top_words(lda_tfidf_limit, tfidf_feature_names_limit, num_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5745f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
